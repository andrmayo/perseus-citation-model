{
  "best_global_step": 44380,
  "best_metric": 0.9641027886004465,
  "best_model_checkpoint": "/home/andrew/Projects/perseus-citation-model/outputs/extraction/checkpoint-44380",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 44380,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011266336187471835,
      "grad_norm": 0.8160327076911926,
      "learning_rate": 6.69220369535827e-07,
      "loss": 0.084,
      "step": 100
    },
    {
      "epoch": 0.02253267237494367,
      "grad_norm": 0.5095726847648621,
      "learning_rate": 1.345200540784137e-06,
      "loss": 0.0689,
      "step": 200
    },
    {
      "epoch": 0.0337990085624155,
      "grad_norm": 0.22575323283672333,
      "learning_rate": 2.021180712032447e-06,
      "loss": 0.0358,
      "step": 300
    },
    {
      "epoch": 0.04506534474988734,
      "grad_norm": 0.3241671919822693,
      "learning_rate": 2.697160883280757e-06,
      "loss": 0.037,
      "step": 400
    },
    {
      "epoch": 0.05633168093735917,
      "grad_norm": 0.28065627813339233,
      "learning_rate": 3.3731410545290674e-06,
      "loss": 0.0227,
      "step": 500
    },
    {
      "epoch": 0.067598017124831,
      "grad_norm": 0.14276771247386932,
      "learning_rate": 4.049121225777377e-06,
      "loss": 0.0222,
      "step": 600
    },
    {
      "epoch": 0.07886435331230283,
      "grad_norm": 0.427253395318985,
      "learning_rate": 4.725101397025688e-06,
      "loss": 0.0287,
      "step": 700
    },
    {
      "epoch": 0.09013068949977468,
      "grad_norm": 0.05431601405143738,
      "learning_rate": 5.401081568273997e-06,
      "loss": 0.0179,
      "step": 800
    },
    {
      "epoch": 0.10139702568724651,
      "grad_norm": 0.5259154438972473,
      "learning_rate": 6.077061739522308e-06,
      "loss": 0.0146,
      "step": 900
    },
    {
      "epoch": 0.11266336187471834,
      "grad_norm": 0.28960442543029785,
      "learning_rate": 6.753041910770617e-06,
      "loss": 0.015,
      "step": 1000
    },
    {
      "epoch": 0.12392969806219017,
      "grad_norm": 0.4312761127948761,
      "learning_rate": 7.429022082018928e-06,
      "loss": 0.0156,
      "step": 1100
    },
    {
      "epoch": 0.135196034249662,
      "grad_norm": 0.3849887251853943,
      "learning_rate": 8.105002253267239e-06,
      "loss": 0.0134,
      "step": 1200
    },
    {
      "epoch": 0.14646237043713384,
      "grad_norm": 0.1678982526063919,
      "learning_rate": 8.780982424515548e-06,
      "loss": 0.014,
      "step": 1300
    },
    {
      "epoch": 0.15772870662460567,
      "grad_norm": 0.11268344521522522,
      "learning_rate": 9.456962595763858e-06,
      "loss": 0.0149,
      "step": 1400
    },
    {
      "epoch": 0.1689950428120775,
      "grad_norm": 0.4189135432243347,
      "learning_rate": 1.0132942767012168e-05,
      "loss": 0.0106,
      "step": 1500
    },
    {
      "epoch": 0.18026137899954936,
      "grad_norm": 0.12497606873512268,
      "learning_rate": 1.0808922938260477e-05,
      "loss": 0.0125,
      "step": 1600
    },
    {
      "epoch": 0.1915277151870212,
      "grad_norm": 0.09515026211738586,
      "learning_rate": 1.1484903109508787e-05,
      "loss": 0.0087,
      "step": 1700
    },
    {
      "epoch": 0.20279405137449302,
      "grad_norm": 0.23861651122570038,
      "learning_rate": 1.2160883280757098e-05,
      "loss": 0.0094,
      "step": 1800
    },
    {
      "epoch": 0.21406038756196485,
      "grad_norm": 0.5757195949554443,
      "learning_rate": 1.2836863452005408e-05,
      "loss": 0.0106,
      "step": 1900
    },
    {
      "epoch": 0.22532672374943669,
      "grad_norm": 0.0397140309214592,
      "learning_rate": 1.3512843623253719e-05,
      "loss": 0.0067,
      "step": 2000
    },
    {
      "epoch": 0.23659305993690852,
      "grad_norm": 0.8607734441757202,
      "learning_rate": 1.4188823794502029e-05,
      "loss": 0.0124,
      "step": 2100
    },
    {
      "epoch": 0.24785939612438035,
      "grad_norm": 0.16002283990383148,
      "learning_rate": 1.486480396575034e-05,
      "loss": 0.0094,
      "step": 2200
    },
    {
      "epoch": 0.2591257323118522,
      "grad_norm": 0.13102449476718903,
      "learning_rate": 1.5540784136998646e-05,
      "loss": 0.0122,
      "step": 2300
    },
    {
      "epoch": 0.270392068499324,
      "grad_norm": 0.07894182950258255,
      "learning_rate": 1.621676430824696e-05,
      "loss": 0.0067,
      "step": 2400
    },
    {
      "epoch": 0.28165840468679587,
      "grad_norm": 0.11865634471178055,
      "learning_rate": 1.689274447949527e-05,
      "loss": 0.0066,
      "step": 2500
    },
    {
      "epoch": 0.2929247408742677,
      "grad_norm": 0.099365234375,
      "learning_rate": 1.7568724650743577e-05,
      "loss": 0.0065,
      "step": 2600
    },
    {
      "epoch": 0.30419107706173953,
      "grad_norm": 0.18024876713752747,
      "learning_rate": 1.824470482199189e-05,
      "loss": 0.0097,
      "step": 2700
    },
    {
      "epoch": 0.31545741324921134,
      "grad_norm": 0.03208096697926521,
      "learning_rate": 1.8920684993240198e-05,
      "loss": 0.0079,
      "step": 2800
    },
    {
      "epoch": 0.3267237494366832,
      "grad_norm": 0.31613242626190186,
      "learning_rate": 1.959666516448851e-05,
      "loss": 0.0067,
      "step": 2900
    },
    {
      "epoch": 0.337990085624155,
      "grad_norm": 0.032068103551864624,
      "learning_rate": 2.027264533573682e-05,
      "loss": 0.0057,
      "step": 3000
    },
    {
      "epoch": 0.34925642181162686,
      "grad_norm": 0.06310617923736572,
      "learning_rate": 2.094862550698513e-05,
      "loss": 0.0075,
      "step": 3100
    },
    {
      "epoch": 0.3605227579990987,
      "grad_norm": 0.24003702402114868,
      "learning_rate": 2.1624605678233436e-05,
      "loss": 0.0109,
      "step": 3200
    },
    {
      "epoch": 0.3717890941865705,
      "grad_norm": 0.10679963231086731,
      "learning_rate": 2.230058584948175e-05,
      "loss": 0.0129,
      "step": 3300
    },
    {
      "epoch": 0.3830554303740424,
      "grad_norm": 0.38257327675819397,
      "learning_rate": 2.2976566020730057e-05,
      "loss": 0.0079,
      "step": 3400
    },
    {
      "epoch": 0.3943217665615142,
      "grad_norm": 0.18094180524349213,
      "learning_rate": 2.3652546191978368e-05,
      "loss": 0.0099,
      "step": 3500
    },
    {
      "epoch": 0.40558810274898605,
      "grad_norm": 0.02226603403687477,
      "learning_rate": 2.432852636322668e-05,
      "loss": 0.0076,
      "step": 3600
    },
    {
      "epoch": 0.41685443893645785,
      "grad_norm": 0.09962136298418045,
      "learning_rate": 2.500450653447499e-05,
      "loss": 0.0093,
      "step": 3700
    },
    {
      "epoch": 0.4281207751239297,
      "grad_norm": 0.04775605723261833,
      "learning_rate": 2.5680486705723302e-05,
      "loss": 0.0072,
      "step": 3800
    },
    {
      "epoch": 0.4393871113114015,
      "grad_norm": 0.07452740520238876,
      "learning_rate": 2.635646687697161e-05,
      "loss": 0.0078,
      "step": 3900
    },
    {
      "epoch": 0.45065344749887337,
      "grad_norm": 0.20025411248207092,
      "learning_rate": 2.703244704821992e-05,
      "loss": 0.0078,
      "step": 4000
    },
    {
      "epoch": 0.4619197836863452,
      "grad_norm": 0.41521844267845154,
      "learning_rate": 2.770842721946823e-05,
      "loss": 0.0055,
      "step": 4100
    },
    {
      "epoch": 0.47318611987381703,
      "grad_norm": 0.09241390973329544,
      "learning_rate": 2.838440739071654e-05,
      "loss": 0.0087,
      "step": 4200
    },
    {
      "epoch": 0.4844524560612889,
      "grad_norm": 0.05360008031129837,
      "learning_rate": 2.9060387561964847e-05,
      "loss": 0.0059,
      "step": 4300
    },
    {
      "epoch": 0.4957187922487607,
      "grad_norm": 0.05244407430291176,
      "learning_rate": 2.973636773321316e-05,
      "loss": 0.0074,
      "step": 4400
    },
    {
      "epoch": 0.5069851284362326,
      "grad_norm": 0.0835954025387764,
      "learning_rate": 2.995418356617095e-05,
      "loss": 0.0076,
      "step": 4500
    },
    {
      "epoch": 0.5182514646237044,
      "grad_norm": 0.1011602133512497,
      "learning_rate": 2.987907465825447e-05,
      "loss": 0.0051,
      "step": 4600
    },
    {
      "epoch": 0.5295178008111762,
      "grad_norm": 0.08614977449178696,
      "learning_rate": 2.980396575033799e-05,
      "loss": 0.0087,
      "step": 4700
    },
    {
      "epoch": 0.540784136998648,
      "grad_norm": 0.13907504081726074,
      "learning_rate": 2.9728856842421512e-05,
      "loss": 0.0071,
      "step": 4800
    },
    {
      "epoch": 0.5520504731861199,
      "grad_norm": 0.0625932440161705,
      "learning_rate": 2.9653747934505032e-05,
      "loss": 0.0084,
      "step": 4900
    },
    {
      "epoch": 0.5633168093735917,
      "grad_norm": 0.0737442895770073,
      "learning_rate": 2.9578639026588556e-05,
      "loss": 0.0056,
      "step": 5000
    },
    {
      "epoch": 0.5745831455610635,
      "grad_norm": 0.6609907150268555,
      "learning_rate": 2.9503530118672076e-05,
      "loss": 0.006,
      "step": 5100
    },
    {
      "epoch": 0.5858494817485354,
      "grad_norm": 0.037693317979574203,
      "learning_rate": 2.9428421210755596e-05,
      "loss": 0.0047,
      "step": 5200
    },
    {
      "epoch": 0.5971158179360072,
      "grad_norm": 0.4387032091617584,
      "learning_rate": 2.935331230283912e-05,
      "loss": 0.0069,
      "step": 5300
    },
    {
      "epoch": 0.6083821541234791,
      "grad_norm": 0.07323846966028214,
      "learning_rate": 2.927820339492264e-05,
      "loss": 0.0087,
      "step": 5400
    },
    {
      "epoch": 0.6196484903109509,
      "grad_norm": 0.16026128828525543,
      "learning_rate": 2.9203094487006162e-05,
      "loss": 0.0056,
      "step": 5500
    },
    {
      "epoch": 0.6309148264984227,
      "grad_norm": 0.1703704595565796,
      "learning_rate": 2.9127985579089682e-05,
      "loss": 0.0078,
      "step": 5600
    },
    {
      "epoch": 0.6421811626858945,
      "grad_norm": 0.1819530427455902,
      "learning_rate": 2.9052876671173202e-05,
      "loss": 0.0063,
      "step": 5700
    },
    {
      "epoch": 0.6534474988733664,
      "grad_norm": 0.14284372329711914,
      "learning_rate": 2.8977767763256725e-05,
      "loss": 0.0084,
      "step": 5800
    },
    {
      "epoch": 0.6647138350608383,
      "grad_norm": 0.06259318441152573,
      "learning_rate": 2.8902658855340245e-05,
      "loss": 0.0132,
      "step": 5900
    },
    {
      "epoch": 0.67598017124831,
      "grad_norm": 0.6821666359901428,
      "learning_rate": 2.8827549947423765e-05,
      "loss": 0.0083,
      "step": 6000
    },
    {
      "epoch": 0.6872465074357819,
      "grad_norm": 0.5349125266075134,
      "learning_rate": 2.8752441039507285e-05,
      "loss": 0.0098,
      "step": 6100
    },
    {
      "epoch": 0.6985128436232537,
      "grad_norm": 0.07278217375278473,
      "learning_rate": 2.8677332131590805e-05,
      "loss": 0.0066,
      "step": 6200
    },
    {
      "epoch": 0.7097791798107256,
      "grad_norm": 0.24542899429798126,
      "learning_rate": 2.860222322367433e-05,
      "loss": 0.0085,
      "step": 6300
    },
    {
      "epoch": 0.7210455159981974,
      "grad_norm": 1.452921748161316,
      "learning_rate": 2.852711431575785e-05,
      "loss": 0.0079,
      "step": 6400
    },
    {
      "epoch": 0.7323118521856692,
      "grad_norm": 0.12714101374149323,
      "learning_rate": 2.845200540784137e-05,
      "loss": 0.0063,
      "step": 6500
    },
    {
      "epoch": 0.743578188373141,
      "grad_norm": 0.059465400874614716,
      "learning_rate": 2.837689649992489e-05,
      "loss": 0.0078,
      "step": 6600
    },
    {
      "epoch": 0.7548445245606129,
      "grad_norm": 0.034070566296577454,
      "learning_rate": 2.830178759200841e-05,
      "loss": 0.005,
      "step": 6700
    },
    {
      "epoch": 0.7661108607480848,
      "grad_norm": 0.012044845148921013,
      "learning_rate": 2.8226678684091935e-05,
      "loss": 0.0086,
      "step": 6800
    },
    {
      "epoch": 0.7773771969355565,
      "grad_norm": 0.12146726995706558,
      "learning_rate": 2.8151569776175455e-05,
      "loss": 0.0059,
      "step": 6900
    },
    {
      "epoch": 0.7886435331230284,
      "grad_norm": 0.08552957326173782,
      "learning_rate": 2.8076460868258975e-05,
      "loss": 0.0057,
      "step": 7000
    },
    {
      "epoch": 0.7999098693105002,
      "grad_norm": 0.07182042300701141,
      "learning_rate": 2.8001351960342498e-05,
      "loss": 0.007,
      "step": 7100
    },
    {
      "epoch": 0.8111762054979721,
      "grad_norm": 0.06680291146039963,
      "learning_rate": 2.7926243052426018e-05,
      "loss": 0.0085,
      "step": 7200
    },
    {
      "epoch": 0.8224425416854438,
      "grad_norm": 0.4973258972167969,
      "learning_rate": 2.7851134144509538e-05,
      "loss": 0.0068,
      "step": 7300
    },
    {
      "epoch": 0.8337088778729157,
      "grad_norm": 0.0791112557053566,
      "learning_rate": 2.777602523659306e-05,
      "loss": 0.0055,
      "step": 7400
    },
    {
      "epoch": 0.8449752140603876,
      "grad_norm": 0.6634122729301453,
      "learning_rate": 2.770091632867658e-05,
      "loss": 0.0061,
      "step": 7500
    },
    {
      "epoch": 0.8562415502478594,
      "grad_norm": 0.12110833823680878,
      "learning_rate": 2.7625807420760105e-05,
      "loss": 0.0045,
      "step": 7600
    },
    {
      "epoch": 0.8675078864353313,
      "grad_norm": 0.04918503388762474,
      "learning_rate": 2.7550698512843625e-05,
      "loss": 0.0045,
      "step": 7700
    },
    {
      "epoch": 0.878774222622803,
      "grad_norm": 0.005308832507580519,
      "learning_rate": 2.7475589604927144e-05,
      "loss": 0.0061,
      "step": 7800
    },
    {
      "epoch": 0.8900405588102749,
      "grad_norm": 0.14685866236686707,
      "learning_rate": 2.7400480697010668e-05,
      "loss": 0.0064,
      "step": 7900
    },
    {
      "epoch": 0.9013068949977467,
      "grad_norm": 0.12978555262088776,
      "learning_rate": 2.7325371789094188e-05,
      "loss": 0.0042,
      "step": 8000
    },
    {
      "epoch": 0.9125732311852186,
      "grad_norm": 0.038266122341156006,
      "learning_rate": 2.725026288117771e-05,
      "loss": 0.0049,
      "step": 8100
    },
    {
      "epoch": 0.9238395673726904,
      "grad_norm": 0.11784172058105469,
      "learning_rate": 2.717515397326123e-05,
      "loss": 0.0048,
      "step": 8200
    },
    {
      "epoch": 0.9351059035601622,
      "grad_norm": 0.002032390097156167,
      "learning_rate": 2.710004506534475e-05,
      "loss": 0.0078,
      "step": 8300
    },
    {
      "epoch": 0.9463722397476341,
      "grad_norm": 0.15386000275611877,
      "learning_rate": 2.7024936157428274e-05,
      "loss": 0.0061,
      "step": 8400
    },
    {
      "epoch": 0.9576385759351059,
      "grad_norm": 0.13995452225208282,
      "learning_rate": 2.6949827249511794e-05,
      "loss": 0.0081,
      "step": 8500
    },
    {
      "epoch": 0.9689049121225778,
      "grad_norm": 0.46062132716178894,
      "learning_rate": 2.687471834159531e-05,
      "loss": 0.0093,
      "step": 8600
    },
    {
      "epoch": 0.9801712483100495,
      "grad_norm": 0.07096676528453827,
      "learning_rate": 2.6799609433678834e-05,
      "loss": 0.0054,
      "step": 8700
    },
    {
      "epoch": 0.9914375844975214,
      "grad_norm": 0.05322512611746788,
      "learning_rate": 2.6724500525762354e-05,
      "loss": 0.0042,
      "step": 8800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9986104949330408,
      "eval_f1": 0.9555652363319538,
      "eval_loss": 0.0046512894332408905,
      "eval_precision": 0.944985352403929,
      "eval_recall": 0.9663847034981056,
      "eval_runtime": 158.6264,
      "eval_samples_per_second": 93.131,
      "eval_steps_per_second": 2.913,
      "step": 8876
    },
    {
      "epoch": 1.0027039206849933,
      "grad_norm": 0.02402590773999691,
      "learning_rate": 2.6649391617845877e-05,
      "loss": 0.0071,
      "step": 8900
    },
    {
      "epoch": 1.0139702568724651,
      "grad_norm": 0.11008621007204056,
      "learning_rate": 2.6574282709929397e-05,
      "loss": 0.0048,
      "step": 9000
    },
    {
      "epoch": 1.025236593059937,
      "grad_norm": 0.03143668174743652,
      "learning_rate": 2.6499173802012917e-05,
      "loss": 0.0037,
      "step": 9100
    },
    {
      "epoch": 1.0365029292474088,
      "grad_norm": 0.1710585653781891,
      "learning_rate": 2.642406489409644e-05,
      "loss": 0.0041,
      "step": 9200
    },
    {
      "epoch": 1.0477692654348805,
      "grad_norm": 0.0818963348865509,
      "learning_rate": 2.634895598617996e-05,
      "loss": 0.0036,
      "step": 9300
    },
    {
      "epoch": 1.0590356016223523,
      "grad_norm": 0.3665221333503723,
      "learning_rate": 2.6273847078263484e-05,
      "loss": 0.0029,
      "step": 9400
    },
    {
      "epoch": 1.0703019378098242,
      "grad_norm": 0.1535189300775528,
      "learning_rate": 2.6198738170347004e-05,
      "loss": 0.0037,
      "step": 9500
    },
    {
      "epoch": 1.081568273997296,
      "grad_norm": 0.08276776969432831,
      "learning_rate": 2.6123629262430524e-05,
      "loss": 0.0059,
      "step": 9600
    },
    {
      "epoch": 1.092834610184768,
      "grad_norm": 0.16130933165550232,
      "learning_rate": 2.6048520354514047e-05,
      "loss": 0.0054,
      "step": 9700
    },
    {
      "epoch": 1.1041009463722398,
      "grad_norm": 0.13938137888908386,
      "learning_rate": 2.5973411446597567e-05,
      "loss": 0.0067,
      "step": 9800
    },
    {
      "epoch": 1.1153672825597116,
      "grad_norm": 0.21711580455303192,
      "learning_rate": 2.5898302538681087e-05,
      "loss": 0.0055,
      "step": 9900
    },
    {
      "epoch": 1.1266336187471835,
      "grad_norm": 0.2799777686595917,
      "learning_rate": 2.582319363076461e-05,
      "loss": 0.0037,
      "step": 10000
    },
    {
      "epoch": 1.1378999549346553,
      "grad_norm": 0.04033394530415535,
      "learning_rate": 2.574808472284813e-05,
      "loss": 0.0046,
      "step": 10100
    },
    {
      "epoch": 1.149166291122127,
      "grad_norm": 0.21510766446590424,
      "learning_rate": 2.5672975814931653e-05,
      "loss": 0.0038,
      "step": 10200
    },
    {
      "epoch": 1.1604326273095988,
      "grad_norm": 0.05123767629265785,
      "learning_rate": 2.5597866907015173e-05,
      "loss": 0.0045,
      "step": 10300
    },
    {
      "epoch": 1.1716989634970707,
      "grad_norm": 0.004996693227440119,
      "learning_rate": 2.5522757999098693e-05,
      "loss": 0.0054,
      "step": 10400
    },
    {
      "epoch": 1.1829652996845426,
      "grad_norm": 0.18182286620140076,
      "learning_rate": 2.5447649091182217e-05,
      "loss": 0.004,
      "step": 10500
    },
    {
      "epoch": 1.1942316358720144,
      "grad_norm": 0.10650169849395752,
      "learning_rate": 2.5372540183265737e-05,
      "loss": 0.004,
      "step": 10600
    },
    {
      "epoch": 1.2054979720594863,
      "grad_norm": 0.10364769399166107,
      "learning_rate": 2.529743127534926e-05,
      "loss": 0.0043,
      "step": 10700
    },
    {
      "epoch": 1.2167643082469581,
      "grad_norm": 0.35686010122299194,
      "learning_rate": 2.522232236743278e-05,
      "loss": 0.0049,
      "step": 10800
    },
    {
      "epoch": 1.22803064443443,
      "grad_norm": 0.019733263179659843,
      "learning_rate": 2.51472134595163e-05,
      "loss": 0.0076,
      "step": 10900
    },
    {
      "epoch": 1.2392969806219019,
      "grad_norm": 0.04488822817802429,
      "learning_rate": 2.5072104551599823e-05,
      "loss": 0.0043,
      "step": 11000
    },
    {
      "epoch": 1.2505633168093735,
      "grad_norm": 0.06971316039562225,
      "learning_rate": 2.499699564368334e-05,
      "loss": 0.004,
      "step": 11100
    },
    {
      "epoch": 1.2618296529968454,
      "grad_norm": 0.00826452486217022,
      "learning_rate": 2.492188673576686e-05,
      "loss": 0.0038,
      "step": 11200
    },
    {
      "epoch": 1.2730959891843172,
      "grad_norm": 0.03738216683268547,
      "learning_rate": 2.4846777827850383e-05,
      "loss": 0.0044,
      "step": 11300
    },
    {
      "epoch": 1.284362325371789,
      "grad_norm": 0.1432713121175766,
      "learning_rate": 2.4771668919933903e-05,
      "loss": 0.0038,
      "step": 11400
    },
    {
      "epoch": 1.295628661559261,
      "grad_norm": 0.005326066166162491,
      "learning_rate": 2.4696560012017426e-05,
      "loss": 0.0068,
      "step": 11500
    },
    {
      "epoch": 1.3068949977467328,
      "grad_norm": 0.09411653131246567,
      "learning_rate": 2.4621451104100946e-05,
      "loss": 0.0043,
      "step": 11600
    },
    {
      "epoch": 1.3181613339342046,
      "grad_norm": 0.09904018044471741,
      "learning_rate": 2.4546342196184466e-05,
      "loss": 0.0057,
      "step": 11700
    },
    {
      "epoch": 1.3294276701216765,
      "grad_norm": 0.39747464656829834,
      "learning_rate": 2.447123328826799e-05,
      "loss": 0.0063,
      "step": 11800
    },
    {
      "epoch": 1.3406940063091484,
      "grad_norm": 0.23884090781211853,
      "learning_rate": 2.439612438035151e-05,
      "loss": 0.0061,
      "step": 11900
    },
    {
      "epoch": 1.35196034249662,
      "grad_norm": 0.019708797335624695,
      "learning_rate": 2.432101547243503e-05,
      "loss": 0.0034,
      "step": 12000
    },
    {
      "epoch": 1.3632266786840919,
      "grad_norm": 0.0012166631640866399,
      "learning_rate": 2.4245906564518553e-05,
      "loss": 0.0049,
      "step": 12100
    },
    {
      "epoch": 1.3744930148715637,
      "grad_norm": 0.14697566628456116,
      "learning_rate": 2.4170797656602073e-05,
      "loss": 0.0042,
      "step": 12200
    },
    {
      "epoch": 1.3857593510590356,
      "grad_norm": 0.3873889744281769,
      "learning_rate": 2.4095688748685596e-05,
      "loss": 0.0031,
      "step": 12300
    },
    {
      "epoch": 1.3970256872465074,
      "grad_norm": 0.060384348034858704,
      "learning_rate": 2.4020579840769116e-05,
      "loss": 0.0035,
      "step": 12400
    },
    {
      "epoch": 1.4082920234339793,
      "grad_norm": 0.010888436809182167,
      "learning_rate": 2.3945470932852636e-05,
      "loss": 0.0039,
      "step": 12500
    },
    {
      "epoch": 1.4195583596214512,
      "grad_norm": 0.19132283329963684,
      "learning_rate": 2.387036202493616e-05,
      "loss": 0.0041,
      "step": 12600
    },
    {
      "epoch": 1.430824695808923,
      "grad_norm": 0.044951822608709335,
      "learning_rate": 2.379525311701968e-05,
      "loss": 0.0033,
      "step": 12700
    },
    {
      "epoch": 1.4420910319963949,
      "grad_norm": 0.01850001886487007,
      "learning_rate": 2.3720144209103202e-05,
      "loss": 0.0055,
      "step": 12800
    },
    {
      "epoch": 1.4533573681838665,
      "grad_norm": 0.08127610385417938,
      "learning_rate": 2.3645035301186722e-05,
      "loss": 0.0054,
      "step": 12900
    },
    {
      "epoch": 1.4646237043713384,
      "grad_norm": 0.09042418748140335,
      "learning_rate": 2.3569926393270242e-05,
      "loss": 0.0044,
      "step": 13000
    },
    {
      "epoch": 1.4758900405588102,
      "grad_norm": 0.08664917945861816,
      "learning_rate": 2.3494817485353766e-05,
      "loss": 0.0029,
      "step": 13100
    },
    {
      "epoch": 1.487156376746282,
      "grad_norm": 0.08973193913698196,
      "learning_rate": 2.3419708577437286e-05,
      "loss": 0.0027,
      "step": 13200
    },
    {
      "epoch": 1.498422712933754,
      "grad_norm": 0.06848154217004776,
      "learning_rate": 2.3344599669520805e-05,
      "loss": 0.0034,
      "step": 13300
    },
    {
      "epoch": 1.5096890491212258,
      "grad_norm": 0.037116888910532,
      "learning_rate": 2.326949076160433e-05,
      "loss": 0.0118,
      "step": 13400
    },
    {
      "epoch": 1.5209553853086977,
      "grad_norm": 0.06941506266593933,
      "learning_rate": 2.319438185368785e-05,
      "loss": 0.0051,
      "step": 13500
    },
    {
      "epoch": 1.5322217214961693,
      "grad_norm": 0.13462314009666443,
      "learning_rate": 2.311927294577137e-05,
      "loss": 0.0072,
      "step": 13600
    },
    {
      "epoch": 1.5434880576836414,
      "grad_norm": 0.0647808387875557,
      "learning_rate": 2.304416403785489e-05,
      "loss": 0.0043,
      "step": 13700
    },
    {
      "epoch": 1.554754393871113,
      "grad_norm": 0.07316883653402328,
      "learning_rate": 2.296905512993841e-05,
      "loss": 0.0036,
      "step": 13800
    },
    {
      "epoch": 1.566020730058585,
      "grad_norm": 0.004553399980068207,
      "learning_rate": 2.2893946222021932e-05,
      "loss": 0.0031,
      "step": 13900
    },
    {
      "epoch": 1.5772870662460567,
      "grad_norm": 0.051292773336172104,
      "learning_rate": 2.2818837314105452e-05,
      "loss": 0.0047,
      "step": 14000
    },
    {
      "epoch": 1.5885534024335286,
      "grad_norm": 0.07639794796705246,
      "learning_rate": 2.2743728406188975e-05,
      "loss": 0.0043,
      "step": 14100
    },
    {
      "epoch": 1.5998197386210005,
      "grad_norm": 0.026096466928720474,
      "learning_rate": 2.2668619498272495e-05,
      "loss": 0.0037,
      "step": 14200
    },
    {
      "epoch": 1.6110860748084723,
      "grad_norm": 0.09260393679141998,
      "learning_rate": 2.2593510590356015e-05,
      "loss": 0.0048,
      "step": 14300
    },
    {
      "epoch": 1.6223524109959442,
      "grad_norm": 0.05189857631921768,
      "learning_rate": 2.251840168243954e-05,
      "loss": 0.0033,
      "step": 14400
    },
    {
      "epoch": 1.6336187471834158,
      "grad_norm": 0.2984628677368164,
      "learning_rate": 2.2443292774523058e-05,
      "loss": 0.0038,
      "step": 14500
    },
    {
      "epoch": 1.644885083370888,
      "grad_norm": 0.03887343034148216,
      "learning_rate": 2.2368183866606578e-05,
      "loss": 0.0036,
      "step": 14600
    },
    {
      "epoch": 1.6561514195583595,
      "grad_norm": 0.005229225382208824,
      "learning_rate": 2.22930749586901e-05,
      "loss": 0.0043,
      "step": 14700
    },
    {
      "epoch": 1.6674177557458316,
      "grad_norm": 0.014828365296125412,
      "learning_rate": 2.221796605077362e-05,
      "loss": 0.0053,
      "step": 14800
    },
    {
      "epoch": 1.6786840919333033,
      "grad_norm": 0.04927990585565567,
      "learning_rate": 2.2142857142857145e-05,
      "loss": 0.0042,
      "step": 14900
    },
    {
      "epoch": 1.6899504281207751,
      "grad_norm": 0.6238682270050049,
      "learning_rate": 2.2067748234940665e-05,
      "loss": 0.0036,
      "step": 15000
    },
    {
      "epoch": 1.701216764308247,
      "grad_norm": 0.16417862474918365,
      "learning_rate": 2.1992639327024185e-05,
      "loss": 0.0059,
      "step": 15100
    },
    {
      "epoch": 1.7124831004957188,
      "grad_norm": 0.26745036244392395,
      "learning_rate": 2.1917530419107708e-05,
      "loss": 0.0064,
      "step": 15200
    },
    {
      "epoch": 1.7237494366831907,
      "grad_norm": 0.032645903527736664,
      "learning_rate": 2.1842421511191228e-05,
      "loss": 0.0046,
      "step": 15300
    },
    {
      "epoch": 1.7350157728706623,
      "grad_norm": 0.28800439834594727,
      "learning_rate": 2.176731260327475e-05,
      "loss": 0.0051,
      "step": 15400
    },
    {
      "epoch": 1.7462821090581344,
      "grad_norm": 0.029413029551506042,
      "learning_rate": 2.169220369535827e-05,
      "loss": 0.0031,
      "step": 15500
    },
    {
      "epoch": 1.757548445245606,
      "grad_norm": 0.04710403084754944,
      "learning_rate": 2.161709478744179e-05,
      "loss": 0.0041,
      "step": 15600
    },
    {
      "epoch": 1.768814781433078,
      "grad_norm": 0.12499841302633286,
      "learning_rate": 2.1541985879525314e-05,
      "loss": 0.0038,
      "step": 15700
    },
    {
      "epoch": 1.7800811176205498,
      "grad_norm": 0.05809597671031952,
      "learning_rate": 2.1466876971608834e-05,
      "loss": 0.0025,
      "step": 15800
    },
    {
      "epoch": 1.7913474538080216,
      "grad_norm": 0.09116779267787933,
      "learning_rate": 2.1391768063692354e-05,
      "loss": 0.003,
      "step": 15900
    },
    {
      "epoch": 1.8026137899954935,
      "grad_norm": 0.03396754711866379,
      "learning_rate": 2.1316659155775878e-05,
      "loss": 0.0058,
      "step": 16000
    },
    {
      "epoch": 1.8138801261829653,
      "grad_norm": 0.11692120134830475,
      "learning_rate": 2.1241550247859398e-05,
      "loss": 0.0076,
      "step": 16100
    },
    {
      "epoch": 1.8251464623704372,
      "grad_norm": 0.08759872615337372,
      "learning_rate": 2.1166441339942918e-05,
      "loss": 0.0031,
      "step": 16200
    },
    {
      "epoch": 1.8364127985579088,
      "grad_norm": 0.013017834164202213,
      "learning_rate": 2.1091332432026437e-05,
      "loss": 0.003,
      "step": 16300
    },
    {
      "epoch": 1.847679134745381,
      "grad_norm": 0.048657163977622986,
      "learning_rate": 2.1016223524109957e-05,
      "loss": 0.0034,
      "step": 16400
    },
    {
      "epoch": 1.8589454709328526,
      "grad_norm": 0.10498327761888504,
      "learning_rate": 2.094111461619348e-05,
      "loss": 0.0032,
      "step": 16500
    },
    {
      "epoch": 1.8702118071203244,
      "grad_norm": 0.19093187153339386,
      "learning_rate": 2.0866005708277e-05,
      "loss": 0.0031,
      "step": 16600
    },
    {
      "epoch": 1.8814781433077963,
      "grad_norm": 0.17985399067401886,
      "learning_rate": 2.0790896800360524e-05,
      "loss": 0.0024,
      "step": 16700
    },
    {
      "epoch": 1.8927444794952681,
      "grad_norm": 0.0031100036576390266,
      "learning_rate": 2.0715787892444044e-05,
      "loss": 0.0041,
      "step": 16800
    },
    {
      "epoch": 1.90401081568274,
      "grad_norm": 0.025558114051818848,
      "learning_rate": 2.0640678984527564e-05,
      "loss": 0.004,
      "step": 16900
    },
    {
      "epoch": 1.9152771518702119,
      "grad_norm": 0.057883042842149734,
      "learning_rate": 2.0565570076611087e-05,
      "loss": 0.0037,
      "step": 17000
    },
    {
      "epoch": 1.9265434880576837,
      "grad_norm": 0.06416665017604828,
      "learning_rate": 2.0490461168694607e-05,
      "loss": 0.003,
      "step": 17100
    },
    {
      "epoch": 1.9378098242451554,
      "grad_norm": 0.06223894655704498,
      "learning_rate": 2.0415352260778127e-05,
      "loss": 0.0073,
      "step": 17200
    },
    {
      "epoch": 1.9490761604326274,
      "grad_norm": 0.011801645159721375,
      "learning_rate": 2.034024335286165e-05,
      "loss": 0.0034,
      "step": 17300
    },
    {
      "epoch": 1.960342496620099,
      "grad_norm": 0.06844571232795715,
      "learning_rate": 2.026513444494517e-05,
      "loss": 0.0032,
      "step": 17400
    },
    {
      "epoch": 1.971608832807571,
      "grad_norm": 0.12779080867767334,
      "learning_rate": 2.0190025537028694e-05,
      "loss": 0.0047,
      "step": 17500
    },
    {
      "epoch": 1.9828751689950428,
      "grad_norm": 0.03055633045732975,
      "learning_rate": 2.0114916629112214e-05,
      "loss": 0.0029,
      "step": 17600
    },
    {
      "epoch": 1.9941415051825147,
      "grad_norm": 0.03284047916531563,
      "learning_rate": 2.0039807721195734e-05,
      "loss": 0.0048,
      "step": 17700
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9986295447130793,
      "eval_f1": 0.9542551579311987,
      "eval_loss": 0.005395222455263138,
      "eval_precision": 0.9381092240241774,
      "eval_recall": 0.9709666049872235,
      "eval_runtime": 159.4885,
      "eval_samples_per_second": 92.627,
      "eval_steps_per_second": 2.897,
      "step": 17752
    },
    {
      "epoch": 2.0054078413699865,
      "grad_norm": 0.031886689364910126,
      "learning_rate": 1.9964698813279257e-05,
      "loss": 0.0028,
      "step": 17800
    },
    {
      "epoch": 2.016674177557458,
      "grad_norm": 0.021753577515482903,
      "learning_rate": 1.9889589905362777e-05,
      "loss": 0.0029,
      "step": 17900
    },
    {
      "epoch": 2.0279405137449302,
      "grad_norm": 0.017871152609586716,
      "learning_rate": 1.98144809974463e-05,
      "loss": 0.0019,
      "step": 18000
    },
    {
      "epoch": 2.039206849932402,
      "grad_norm": 0.007668085861951113,
      "learning_rate": 1.973937208952982e-05,
      "loss": 0.0029,
      "step": 18100
    },
    {
      "epoch": 2.050473186119874,
      "grad_norm": 0.03223160281777382,
      "learning_rate": 1.966426318161334e-05,
      "loss": 0.0027,
      "step": 18200
    },
    {
      "epoch": 2.0617395223073456,
      "grad_norm": 0.00992358848452568,
      "learning_rate": 1.9589154273696863e-05,
      "loss": 0.0031,
      "step": 18300
    },
    {
      "epoch": 2.0730058584948177,
      "grad_norm": 0.03190811350941658,
      "learning_rate": 1.9514045365780383e-05,
      "loss": 0.0021,
      "step": 18400
    },
    {
      "epoch": 2.0842721946822893,
      "grad_norm": 0.045840341597795486,
      "learning_rate": 1.9438936457863903e-05,
      "loss": 0.0052,
      "step": 18500
    },
    {
      "epoch": 2.095538530869761,
      "grad_norm": 0.048879604786634445,
      "learning_rate": 1.9363827549947427e-05,
      "loss": 0.0023,
      "step": 18600
    },
    {
      "epoch": 2.106804867057233,
      "grad_norm": 0.022747686132788658,
      "learning_rate": 1.9288718642030943e-05,
      "loss": 0.003,
      "step": 18700
    },
    {
      "epoch": 2.1180712032447047,
      "grad_norm": 0.11992166936397552,
      "learning_rate": 1.9213609734114466e-05,
      "loss": 0.0023,
      "step": 18800
    },
    {
      "epoch": 2.1293375394321767,
      "grad_norm": 0.03244495391845703,
      "learning_rate": 1.9138500826197986e-05,
      "loss": 0.002,
      "step": 18900
    },
    {
      "epoch": 2.1406038756196484,
      "grad_norm": 0.4501504898071289,
      "learning_rate": 1.9063391918281506e-05,
      "loss": 0.0024,
      "step": 19000
    },
    {
      "epoch": 2.1518702118071205,
      "grad_norm": 0.013278457336127758,
      "learning_rate": 1.898828301036503e-05,
      "loss": 0.0032,
      "step": 19100
    },
    {
      "epoch": 2.163136547994592,
      "grad_norm": 0.05377601087093353,
      "learning_rate": 1.891317410244855e-05,
      "loss": 0.0019,
      "step": 19200
    },
    {
      "epoch": 2.174402884182064,
      "grad_norm": 0.11380729079246521,
      "learning_rate": 1.883806519453207e-05,
      "loss": 0.0024,
      "step": 19300
    },
    {
      "epoch": 2.185669220369536,
      "grad_norm": 0.00743678817525506,
      "learning_rate": 1.8762956286615593e-05,
      "loss": 0.0022,
      "step": 19400
    },
    {
      "epoch": 2.1969355565570075,
      "grad_norm": 0.17114363610744476,
      "learning_rate": 1.8687847378699113e-05,
      "loss": 0.0018,
      "step": 19500
    },
    {
      "epoch": 2.2082018927444795,
      "grad_norm": 0.100393146276474,
      "learning_rate": 1.8612738470782636e-05,
      "loss": 0.0028,
      "step": 19600
    },
    {
      "epoch": 2.219468228931951,
      "grad_norm": 0.07422857731580734,
      "learning_rate": 1.8537629562866156e-05,
      "loss": 0.0023,
      "step": 19700
    },
    {
      "epoch": 2.2307345651194233,
      "grad_norm": 0.08426231890916824,
      "learning_rate": 1.8462520654949676e-05,
      "loss": 0.0018,
      "step": 19800
    },
    {
      "epoch": 2.242000901306895,
      "grad_norm": 0.42581671476364136,
      "learning_rate": 1.83874117470332e-05,
      "loss": 0.0029,
      "step": 19900
    },
    {
      "epoch": 2.253267237494367,
      "grad_norm": 0.043625425547361374,
      "learning_rate": 1.831230283911672e-05,
      "loss": 0.0042,
      "step": 20000
    },
    {
      "epoch": 2.2645335736818386,
      "grad_norm": 0.13215065002441406,
      "learning_rate": 1.8237193931200243e-05,
      "loss": 0.0024,
      "step": 20100
    },
    {
      "epoch": 2.2757999098693107,
      "grad_norm": 0.03807707503437996,
      "learning_rate": 1.8162085023283763e-05,
      "loss": 0.002,
      "step": 20200
    },
    {
      "epoch": 2.2870662460567823,
      "grad_norm": 0.08493570238351822,
      "learning_rate": 1.8086976115367282e-05,
      "loss": 0.0019,
      "step": 20300
    },
    {
      "epoch": 2.298332582244254,
      "grad_norm": 0.021086551249027252,
      "learning_rate": 1.8011867207450806e-05,
      "loss": 0.0026,
      "step": 20400
    },
    {
      "epoch": 2.309598918431726,
      "grad_norm": 0.06439168751239777,
      "learning_rate": 1.7936758299534326e-05,
      "loss": 0.0031,
      "step": 20500
    },
    {
      "epoch": 2.3208652546191977,
      "grad_norm": 0.00609779404476285,
      "learning_rate": 1.7861649391617846e-05,
      "loss": 0.0027,
      "step": 20600
    },
    {
      "epoch": 2.3321315908066698,
      "grad_norm": 0.01271885260939598,
      "learning_rate": 1.778654048370137e-05,
      "loss": 0.0021,
      "step": 20700
    },
    {
      "epoch": 2.3433979269941414,
      "grad_norm": 0.051009174436330795,
      "learning_rate": 1.771143157578489e-05,
      "loss": 0.0019,
      "step": 20800
    },
    {
      "epoch": 2.3546642631816135,
      "grad_norm": 0.044829849153757095,
      "learning_rate": 1.7636322667868412e-05,
      "loss": 0.003,
      "step": 20900
    },
    {
      "epoch": 2.365930599369085,
      "grad_norm": 0.08013974130153656,
      "learning_rate": 1.7561213759951932e-05,
      "loss": 0.0026,
      "step": 21000
    },
    {
      "epoch": 2.377196935556557,
      "grad_norm": 0.05963359773159027,
      "learning_rate": 1.7486104852035452e-05,
      "loss": 0.0032,
      "step": 21100
    },
    {
      "epoch": 2.388463271744029,
      "grad_norm": 0.092984639108181,
      "learning_rate": 1.7410995944118972e-05,
      "loss": 0.0029,
      "step": 21200
    },
    {
      "epoch": 2.3997296079315005,
      "grad_norm": 0.5301902294158936,
      "learning_rate": 1.7335887036202492e-05,
      "loss": 0.0029,
      "step": 21300
    },
    {
      "epoch": 2.4109959441189726,
      "grad_norm": 0.06026775762438774,
      "learning_rate": 1.7260778128286015e-05,
      "loss": 0.002,
      "step": 21400
    },
    {
      "epoch": 2.422262280306444,
      "grad_norm": 0.3029111921787262,
      "learning_rate": 1.7185669220369535e-05,
      "loss": 0.0021,
      "step": 21500
    },
    {
      "epoch": 2.4335286164939163,
      "grad_norm": 0.02918279357254505,
      "learning_rate": 1.7110560312453055e-05,
      "loss": 0.0019,
      "step": 21600
    },
    {
      "epoch": 2.444794952681388,
      "grad_norm": 0.006048459559679031,
      "learning_rate": 1.703545140453658e-05,
      "loss": 0.002,
      "step": 21700
    },
    {
      "epoch": 2.45606128886886,
      "grad_norm": 0.07189203798770905,
      "learning_rate": 1.69603424966201e-05,
      "loss": 0.0025,
      "step": 21800
    },
    {
      "epoch": 2.4673276250563316,
      "grad_norm": 0.11423148959875107,
      "learning_rate": 1.688523358870362e-05,
      "loss": 0.0023,
      "step": 21900
    },
    {
      "epoch": 2.4785939612438037,
      "grad_norm": 0.10838460177183151,
      "learning_rate": 1.6810124680787142e-05,
      "loss": 0.0022,
      "step": 22000
    },
    {
      "epoch": 2.4898602974312753,
      "grad_norm": 0.019445423036813736,
      "learning_rate": 1.673501577287066e-05,
      "loss": 0.0022,
      "step": 22100
    },
    {
      "epoch": 2.501126633618747,
      "grad_norm": 0.01704920455813408,
      "learning_rate": 1.6659906864954185e-05,
      "loss": 0.0037,
      "step": 22200
    },
    {
      "epoch": 2.512392969806219,
      "grad_norm": 0.031274646520614624,
      "learning_rate": 1.6584797957037705e-05,
      "loss": 0.002,
      "step": 22300
    },
    {
      "epoch": 2.5236593059936907,
      "grad_norm": 0.1519210785627365,
      "learning_rate": 1.6509689049121225e-05,
      "loss": 0.0029,
      "step": 22400
    },
    {
      "epoch": 2.534925642181163,
      "grad_norm": 0.06343378871679306,
      "learning_rate": 1.6434580141204748e-05,
      "loss": 0.0026,
      "step": 22500
    },
    {
      "epoch": 2.5461919783686344,
      "grad_norm": 0.0123837785795331,
      "learning_rate": 1.6359471233288268e-05,
      "loss": 0.002,
      "step": 22600
    },
    {
      "epoch": 2.5574583145561065,
      "grad_norm": 0.006477291230112314,
      "learning_rate": 1.628436232537179e-05,
      "loss": 0.002,
      "step": 22700
    },
    {
      "epoch": 2.568724650743578,
      "grad_norm": 0.014209052547812462,
      "learning_rate": 1.620925341745531e-05,
      "loss": 0.0025,
      "step": 22800
    },
    {
      "epoch": 2.5799909869310502,
      "grad_norm": 0.09302086383104324,
      "learning_rate": 1.613414450953883e-05,
      "loss": 0.0015,
      "step": 22900
    },
    {
      "epoch": 2.591257323118522,
      "grad_norm": 0.07974687218666077,
      "learning_rate": 1.6059035601622355e-05,
      "loss": 0.0018,
      "step": 23000
    },
    {
      "epoch": 2.6025236593059935,
      "grad_norm": 0.010667475871741772,
      "learning_rate": 1.5983926693705875e-05,
      "loss": 0.002,
      "step": 23100
    },
    {
      "epoch": 2.6137899954934656,
      "grad_norm": 0.02221544459462166,
      "learning_rate": 1.5908817785789395e-05,
      "loss": 0.0028,
      "step": 23200
    },
    {
      "epoch": 2.625056331680937,
      "grad_norm": 0.20754191279411316,
      "learning_rate": 1.5833708877872918e-05,
      "loss": 0.0021,
      "step": 23300
    },
    {
      "epoch": 2.6363226678684093,
      "grad_norm": 0.07705790549516678,
      "learning_rate": 1.5758599969956438e-05,
      "loss": 0.002,
      "step": 23400
    },
    {
      "epoch": 2.647589004055881,
      "grad_norm": 0.0030673907604068518,
      "learning_rate": 1.568349106203996e-05,
      "loss": 0.0034,
      "step": 23500
    },
    {
      "epoch": 2.658855340243353,
      "grad_norm": 0.021298155188560486,
      "learning_rate": 1.560838215412348e-05,
      "loss": 0.0018,
      "step": 23600
    },
    {
      "epoch": 2.6701216764308247,
      "grad_norm": 0.08395778387784958,
      "learning_rate": 1.5533273246206998e-05,
      "loss": 0.0031,
      "step": 23700
    },
    {
      "epoch": 2.6813880126182967,
      "grad_norm": 0.11736717075109482,
      "learning_rate": 1.545816433829052e-05,
      "loss": 0.0029,
      "step": 23800
    },
    {
      "epoch": 2.6926543488057684,
      "grad_norm": 0.01205388642847538,
      "learning_rate": 1.538305543037404e-05,
      "loss": 0.0018,
      "step": 23900
    },
    {
      "epoch": 2.70392068499324,
      "grad_norm": 0.020454535260796547,
      "learning_rate": 1.5307946522457564e-05,
      "loss": 0.0023,
      "step": 24000
    },
    {
      "epoch": 2.715187021180712,
      "grad_norm": 0.06282120198011398,
      "learning_rate": 1.5232837614541086e-05,
      "loss": 0.0027,
      "step": 24100
    },
    {
      "epoch": 2.7264533573681837,
      "grad_norm": 0.02513750083744526,
      "learning_rate": 1.5157728706624606e-05,
      "loss": 0.0028,
      "step": 24200
    },
    {
      "epoch": 2.737719693555656,
      "grad_norm": 0.017204128205776215,
      "learning_rate": 1.5082619798708127e-05,
      "loss": 0.0025,
      "step": 24300
    },
    {
      "epoch": 2.7489860297431274,
      "grad_norm": 0.2763439416885376,
      "learning_rate": 1.5007510890791647e-05,
      "loss": 0.0017,
      "step": 24400
    },
    {
      "epoch": 2.7602523659305995,
      "grad_norm": 0.0021015717647969723,
      "learning_rate": 1.4932401982875169e-05,
      "loss": 0.0037,
      "step": 24500
    },
    {
      "epoch": 2.771518702118071,
      "grad_norm": 0.016006603837013245,
      "learning_rate": 1.485729307495869e-05,
      "loss": 0.0031,
      "step": 24600
    },
    {
      "epoch": 2.7827850383055432,
      "grad_norm": 0.03056342341005802,
      "learning_rate": 1.478218416704221e-05,
      "loss": 0.0024,
      "step": 24700
    },
    {
      "epoch": 2.794051374493015,
      "grad_norm": 0.07966893166303635,
      "learning_rate": 1.4707075259125732e-05,
      "loss": 0.0029,
      "step": 24800
    },
    {
      "epoch": 2.8053177106804865,
      "grad_norm": 0.032201193273067474,
      "learning_rate": 1.4631966351209254e-05,
      "loss": 0.0018,
      "step": 24900
    },
    {
      "epoch": 2.8165840468679586,
      "grad_norm": 0.00996968150138855,
      "learning_rate": 1.4556857443292775e-05,
      "loss": 0.0027,
      "step": 25000
    },
    {
      "epoch": 2.8278503830554302,
      "grad_norm": 0.006855369079858065,
      "learning_rate": 1.4481748535376295e-05,
      "loss": 0.0034,
      "step": 25100
    },
    {
      "epoch": 2.8391167192429023,
      "grad_norm": 0.006055851466953754,
      "learning_rate": 1.4406639627459817e-05,
      "loss": 0.0015,
      "step": 25200
    },
    {
      "epoch": 2.850383055430374,
      "grad_norm": 0.08611708879470825,
      "learning_rate": 1.4331530719543339e-05,
      "loss": 0.003,
      "step": 25300
    },
    {
      "epoch": 2.861649391617846,
      "grad_norm": 0.061073046177625656,
      "learning_rate": 1.425642181162686e-05,
      "loss": 0.0032,
      "step": 25400
    },
    {
      "epoch": 2.8729157278053177,
      "grad_norm": 0.00073889025952667,
      "learning_rate": 1.4181312903710382e-05,
      "loss": 0.0017,
      "step": 25500
    },
    {
      "epoch": 2.8841820639927898,
      "grad_norm": 0.025339936837553978,
      "learning_rate": 1.41062039957939e-05,
      "loss": 0.0016,
      "step": 25600
    },
    {
      "epoch": 2.8954484001802614,
      "grad_norm": 0.04228781908750534,
      "learning_rate": 1.4031095087877422e-05,
      "loss": 0.002,
      "step": 25700
    },
    {
      "epoch": 2.906714736367733,
      "grad_norm": 0.05539575591683388,
      "learning_rate": 1.3955986179960943e-05,
      "loss": 0.0018,
      "step": 25800
    },
    {
      "epoch": 2.917981072555205,
      "grad_norm": 0.0038340825121849775,
      "learning_rate": 1.3880877272044465e-05,
      "loss": 0.0015,
      "step": 25900
    },
    {
      "epoch": 2.9292474087426768,
      "grad_norm": 0.01698997989296913,
      "learning_rate": 1.3805768364127985e-05,
      "loss": 0.0026,
      "step": 26000
    },
    {
      "epoch": 2.940513744930149,
      "grad_norm": 0.8604616522789001,
      "learning_rate": 1.3730659456211507e-05,
      "loss": 0.0026,
      "step": 26100
    },
    {
      "epoch": 2.9517800811176205,
      "grad_norm": 0.023800695315003395,
      "learning_rate": 1.3655550548295028e-05,
      "loss": 0.0021,
      "step": 26200
    },
    {
      "epoch": 2.9630464173050926,
      "grad_norm": 0.2186731994152069,
      "learning_rate": 1.358044164037855e-05,
      "loss": 0.0021,
      "step": 26300
    },
    {
      "epoch": 2.974312753492564,
      "grad_norm": 0.03922246769070625,
      "learning_rate": 1.350533273246207e-05,
      "loss": 0.0033,
      "step": 26400
    },
    {
      "epoch": 2.9855790896800363,
      "grad_norm": 0.07985812425613403,
      "learning_rate": 1.3430223824545591e-05,
      "loss": 0.002,
      "step": 26500
    },
    {
      "epoch": 2.996845425867508,
      "grad_norm": 0.004382351879030466,
      "learning_rate": 1.3355114916629113e-05,
      "loss": 0.0013,
      "step": 26600
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9987353768244045,
      "eval_f1": 0.9619796645520118,
      "eval_loss": 0.0060454318299889565,
      "eval_precision": 0.9489498499785683,
      "eval_recall": 0.9753722794959908,
      "eval_runtime": 159.2921,
      "eval_samples_per_second": 92.742,
      "eval_steps_per_second": 2.9,
      "step": 26628
    },
    {
      "epoch": 3.0081117620549795,
      "grad_norm": 0.006696090567857027,
      "learning_rate": 1.3280006008712635e-05,
      "loss": 0.0018,
      "step": 26700
    },
    {
      "epoch": 3.0193780982424516,
      "grad_norm": 0.023728711530566216,
      "learning_rate": 1.3204897100796155e-05,
      "loss": 0.0022,
      "step": 26800
    },
    {
      "epoch": 3.0306444344299233,
      "grad_norm": 0.1115519106388092,
      "learning_rate": 1.3129788192879675e-05,
      "loss": 0.0016,
      "step": 26900
    },
    {
      "epoch": 3.0419107706173953,
      "grad_norm": 0.006512823980301619,
      "learning_rate": 1.3054679284963196e-05,
      "loss": 0.0013,
      "step": 27000
    },
    {
      "epoch": 3.053177106804867,
      "grad_norm": 0.06399095058441162,
      "learning_rate": 1.2979570377046718e-05,
      "loss": 0.0012,
      "step": 27100
    },
    {
      "epoch": 3.064443442992339,
      "grad_norm": 0.006458009127527475,
      "learning_rate": 1.290446146913024e-05,
      "loss": 0.0011,
      "step": 27200
    },
    {
      "epoch": 3.0757097791798107,
      "grad_norm": 0.009677889756858349,
      "learning_rate": 1.282935256121376e-05,
      "loss": 0.0018,
      "step": 27300
    },
    {
      "epoch": 3.086976115367283,
      "grad_norm": 0.03346693143248558,
      "learning_rate": 1.2754243653297281e-05,
      "loss": 0.0019,
      "step": 27400
    },
    {
      "epoch": 3.0982424515547544,
      "grad_norm": 0.04068036004900932,
      "learning_rate": 1.2679134745380803e-05,
      "loss": 0.002,
      "step": 27500
    },
    {
      "epoch": 3.109508787742226,
      "grad_norm": 0.05793651193380356,
      "learning_rate": 1.2604025837464324e-05,
      "loss": 0.0013,
      "step": 27600
    },
    {
      "epoch": 3.120775123929698,
      "grad_norm": 0.038923993706703186,
      "learning_rate": 1.2528916929547844e-05,
      "loss": 0.0017,
      "step": 27700
    },
    {
      "epoch": 3.1320414601171698,
      "grad_norm": 0.04450086131691933,
      "learning_rate": 1.2453808021631366e-05,
      "loss": 0.0016,
      "step": 27800
    },
    {
      "epoch": 3.143307796304642,
      "grad_norm": 0.0012173037976026535,
      "learning_rate": 1.2378699113714888e-05,
      "loss": 0.0013,
      "step": 27900
    },
    {
      "epoch": 3.1545741324921135,
      "grad_norm": 0.0019110882421955466,
      "learning_rate": 1.230359020579841e-05,
      "loss": 0.0014,
      "step": 28000
    },
    {
      "epoch": 3.1658404686795856,
      "grad_norm": 0.20892825722694397,
      "learning_rate": 1.2228481297881929e-05,
      "loss": 0.0015,
      "step": 28100
    },
    {
      "epoch": 3.177106804867057,
      "grad_norm": 0.02147219330072403,
      "learning_rate": 1.2153372389965449e-05,
      "loss": 0.0013,
      "step": 28200
    },
    {
      "epoch": 3.1883731410545293,
      "grad_norm": 0.4164727032184601,
      "learning_rate": 1.207826348204897e-05,
      "loss": 0.0016,
      "step": 28300
    },
    {
      "epoch": 3.199639477242001,
      "grad_norm": 0.14288215339183807,
      "learning_rate": 1.2003154574132492e-05,
      "loss": 0.0012,
      "step": 28400
    },
    {
      "epoch": 3.2109058134294726,
      "grad_norm": 0.008436618372797966,
      "learning_rate": 1.1928045666216014e-05,
      "loss": 0.002,
      "step": 28500
    },
    {
      "epoch": 3.2221721496169446,
      "grad_norm": 0.07551952451467514,
      "learning_rate": 1.1852936758299534e-05,
      "loss": 0.002,
      "step": 28600
    },
    {
      "epoch": 3.2334384858044163,
      "grad_norm": 0.004147863015532494,
      "learning_rate": 1.1777827850383056e-05,
      "loss": 0.0016,
      "step": 28700
    },
    {
      "epoch": 3.2447048219918884,
      "grad_norm": 0.02262931317090988,
      "learning_rate": 1.1702718942466577e-05,
      "loss": 0.0014,
      "step": 28800
    },
    {
      "epoch": 3.25597115817936,
      "grad_norm": 0.04075318202376366,
      "learning_rate": 1.1627610034550099e-05,
      "loss": 0.002,
      "step": 28900
    },
    {
      "epoch": 3.267237494366832,
      "grad_norm": 0.031436819583177567,
      "learning_rate": 1.1552501126633619e-05,
      "loss": 0.0012,
      "step": 29000
    },
    {
      "epoch": 3.2785038305543037,
      "grad_norm": 0.010767676867544651,
      "learning_rate": 1.147739221871714e-05,
      "loss": 0.0016,
      "step": 29100
    },
    {
      "epoch": 3.289770166741776,
      "grad_norm": 0.025125373154878616,
      "learning_rate": 1.1402283310800662e-05,
      "loss": 0.0023,
      "step": 29200
    },
    {
      "epoch": 3.3010365029292474,
      "grad_norm": 0.00626102089881897,
      "learning_rate": 1.1327174402884184e-05,
      "loss": 0.0012,
      "step": 29300
    },
    {
      "epoch": 3.312302839116719,
      "grad_norm": 0.022289907559752464,
      "learning_rate": 1.1252065494967702e-05,
      "loss": 0.0017,
      "step": 29400
    },
    {
      "epoch": 3.323569175304191,
      "grad_norm": 0.19896897673606873,
      "learning_rate": 1.1176956587051224e-05,
      "loss": 0.0016,
      "step": 29500
    },
    {
      "epoch": 3.334835511491663,
      "grad_norm": 0.009577198885381222,
      "learning_rate": 1.1101847679134745e-05,
      "loss": 0.0014,
      "step": 29600
    },
    {
      "epoch": 3.346101847679135,
      "grad_norm": 0.0033322081435471773,
      "learning_rate": 1.1026738771218267e-05,
      "loss": 0.0014,
      "step": 29700
    },
    {
      "epoch": 3.3573681838666065,
      "grad_norm": 0.26362505555152893,
      "learning_rate": 1.0951629863301788e-05,
      "loss": 0.0015,
      "step": 29800
    },
    {
      "epoch": 3.3686345200540786,
      "grad_norm": 0.04332564026117325,
      "learning_rate": 1.0876520955385308e-05,
      "loss": 0.0013,
      "step": 29900
    },
    {
      "epoch": 3.3799008562415502,
      "grad_norm": 0.019645197317004204,
      "learning_rate": 1.080141204746883e-05,
      "loss": 0.0018,
      "step": 30000
    },
    {
      "epoch": 3.3911671924290223,
      "grad_norm": 0.022008372470736504,
      "learning_rate": 1.0726303139552352e-05,
      "loss": 0.0016,
      "step": 30100
    },
    {
      "epoch": 3.402433528616494,
      "grad_norm": 0.013269399292767048,
      "learning_rate": 1.0651194231635873e-05,
      "loss": 0.0011,
      "step": 30200
    },
    {
      "epoch": 3.4136998648039656,
      "grad_norm": 0.014764941297471523,
      "learning_rate": 1.0576085323719393e-05,
      "loss": 0.0009,
      "step": 30300
    },
    {
      "epoch": 3.4249662009914377,
      "grad_norm": 0.017520999535918236,
      "learning_rate": 1.0500976415802915e-05,
      "loss": 0.0019,
      "step": 30400
    },
    {
      "epoch": 3.4362325371789093,
      "grad_norm": 0.018802355974912643,
      "learning_rate": 1.0425867507886436e-05,
      "loss": 0.0012,
      "step": 30500
    },
    {
      "epoch": 3.4474988733663814,
      "grad_norm": 0.01670105569064617,
      "learning_rate": 1.0350758599969956e-05,
      "loss": 0.0014,
      "step": 30600
    },
    {
      "epoch": 3.458765209553853,
      "grad_norm": 0.08755054324865341,
      "learning_rate": 1.0275649692053476e-05,
      "loss": 0.0015,
      "step": 30700
    },
    {
      "epoch": 3.470031545741325,
      "grad_norm": 0.0325956754386425,
      "learning_rate": 1.0200540784136998e-05,
      "loss": 0.0013,
      "step": 30800
    },
    {
      "epoch": 3.4812978819287967,
      "grad_norm": 0.16154979169368744,
      "learning_rate": 1.012543187622052e-05,
      "loss": 0.0013,
      "step": 30900
    },
    {
      "epoch": 3.492564218116269,
      "grad_norm": 0.005162527784705162,
      "learning_rate": 1.0050322968304041e-05,
      "loss": 0.0016,
      "step": 31000
    },
    {
      "epoch": 3.5038305543037405,
      "grad_norm": 0.0060627274215221405,
      "learning_rate": 9.975214060387563e-06,
      "loss": 0.0019,
      "step": 31100
    },
    {
      "epoch": 3.515096890491212,
      "grad_norm": 0.004362138453871012,
      "learning_rate": 9.900105152471083e-06,
      "loss": 0.0011,
      "step": 31200
    },
    {
      "epoch": 3.526363226678684,
      "grad_norm": 0.2865540087223053,
      "learning_rate": 9.824996244554604e-06,
      "loss": 0.0021,
      "step": 31300
    },
    {
      "epoch": 3.537629562866156,
      "grad_norm": 0.011314958333969116,
      "learning_rate": 9.749887336638126e-06,
      "loss": 0.0014,
      "step": 31400
    },
    {
      "epoch": 3.548895899053628,
      "grad_norm": 0.062255486845970154,
      "learning_rate": 9.674778428721648e-06,
      "loss": 0.0018,
      "step": 31500
    },
    {
      "epoch": 3.5601622352410995,
      "grad_norm": 0.00986453052610159,
      "learning_rate": 9.599669520805168e-06,
      "loss": 0.0026,
      "step": 31600
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.05342898890376091,
      "learning_rate": 9.52456061288869e-06,
      "loss": 0.0019,
      "step": 31700
    },
    {
      "epoch": 3.5826949076160433,
      "grad_norm": 0.0012596191372722387,
      "learning_rate": 9.449451704972211e-06,
      "loss": 0.0013,
      "step": 31800
    },
    {
      "epoch": 3.5939612438035153,
      "grad_norm": 0.00022342697775457054,
      "learning_rate": 9.374342797055731e-06,
      "loss": 0.0017,
      "step": 31900
    },
    {
      "epoch": 3.605227579990987,
      "grad_norm": 0.000993644236586988,
      "learning_rate": 9.29923388913925e-06,
      "loss": 0.0013,
      "step": 32000
    },
    {
      "epoch": 3.6164939161784586,
      "grad_norm": 0.001849732012487948,
      "learning_rate": 9.224124981222772e-06,
      "loss": 0.0015,
      "step": 32100
    },
    {
      "epoch": 3.6277602523659307,
      "grad_norm": 0.03891949728131294,
      "learning_rate": 9.149016073306294e-06,
      "loss": 0.0018,
      "step": 32200
    },
    {
      "epoch": 3.6390265885534023,
      "grad_norm": 0.0019839305896312,
      "learning_rate": 9.073907165389816e-06,
      "loss": 0.001,
      "step": 32300
    },
    {
      "epoch": 3.6502929247408744,
      "grad_norm": 0.005210937932133675,
      "learning_rate": 8.998798257473337e-06,
      "loss": 0.0016,
      "step": 32400
    },
    {
      "epoch": 3.661559260928346,
      "grad_norm": 0.20769564807415009,
      "learning_rate": 8.923689349556857e-06,
      "loss": 0.0012,
      "step": 32500
    },
    {
      "epoch": 3.6728255971158177,
      "grad_norm": 0.28439828753471375,
      "learning_rate": 8.848580441640379e-06,
      "loss": 0.0016,
      "step": 32600
    },
    {
      "epoch": 3.6840919333032898,
      "grad_norm": 0.034411873668432236,
      "learning_rate": 8.7734715337239e-06,
      "loss": 0.0013,
      "step": 32700
    },
    {
      "epoch": 3.695358269490762,
      "grad_norm": 0.0783749371767044,
      "learning_rate": 8.698362625807422e-06,
      "loss": 0.0013,
      "step": 32800
    },
    {
      "epoch": 3.7066246056782335,
      "grad_norm": 0.006733727175742388,
      "learning_rate": 8.623253717890942e-06,
      "loss": 0.0013,
      "step": 32900
    },
    {
      "epoch": 3.717890941865705,
      "grad_norm": 0.0046135904267430305,
      "learning_rate": 8.548144809974464e-06,
      "loss": 0.001,
      "step": 33000
    },
    {
      "epoch": 3.729157278053177,
      "grad_norm": 0.0026473035104572773,
      "learning_rate": 8.473035902057984e-06,
      "loss": 0.001,
      "step": 33100
    },
    {
      "epoch": 3.740423614240649,
      "grad_norm": 0.04463987424969673,
      "learning_rate": 8.397926994141505e-06,
      "loss": 0.0012,
      "step": 33200
    },
    {
      "epoch": 3.751689950428121,
      "grad_norm": 0.010623767971992493,
      "learning_rate": 8.322818086225025e-06,
      "loss": 0.0013,
      "step": 33300
    },
    {
      "epoch": 3.7629562866155926,
      "grad_norm": 0.048981938511133194,
      "learning_rate": 8.247709178308547e-06,
      "loss": 0.001,
      "step": 33400
    },
    {
      "epoch": 3.774222622803064,
      "grad_norm": 0.021776767447590828,
      "learning_rate": 8.172600270392069e-06,
      "loss": 0.0012,
      "step": 33500
    },
    {
      "epoch": 3.7854889589905363,
      "grad_norm": 0.18853577971458435,
      "learning_rate": 8.09749136247559e-06,
      "loss": 0.0015,
      "step": 33600
    },
    {
      "epoch": 3.7967552951780084,
      "grad_norm": 0.02127883955836296,
      "learning_rate": 8.02238245455911e-06,
      "loss": 0.0015,
      "step": 33700
    },
    {
      "epoch": 3.80802163136548,
      "grad_norm": 0.01682344079017639,
      "learning_rate": 7.947273546642632e-06,
      "loss": 0.0011,
      "step": 33800
    },
    {
      "epoch": 3.8192879675529516,
      "grad_norm": 0.13981232047080994,
      "learning_rate": 7.872164638726153e-06,
      "loss": 0.0011,
      "step": 33900
    },
    {
      "epoch": 3.8305543037404237,
      "grad_norm": 0.018092399463057518,
      "learning_rate": 7.797055730809675e-06,
      "loss": 0.0016,
      "step": 34000
    },
    {
      "epoch": 3.8418206399278954,
      "grad_norm": 0.08160252869129181,
      "learning_rate": 7.721946822893197e-06,
      "loss": 0.0017,
      "step": 34100
    },
    {
      "epoch": 3.8530869761153674,
      "grad_norm": 0.7321715950965881,
      "learning_rate": 7.646837914976717e-06,
      "loss": 0.0019,
      "step": 34200
    },
    {
      "epoch": 3.864353312302839,
      "grad_norm": 0.02369178645312786,
      "learning_rate": 7.571729007060237e-06,
      "loss": 0.001,
      "step": 34300
    },
    {
      "epoch": 3.8756196484903107,
      "grad_norm": 0.005367746576666832,
      "learning_rate": 7.496620099143759e-06,
      "loss": 0.0013,
      "step": 34400
    },
    {
      "epoch": 3.886885984677783,
      "grad_norm": 0.0023352941498160362,
      "learning_rate": 7.42151119122728e-06,
      "loss": 0.0011,
      "step": 34500
    },
    {
      "epoch": 3.898152320865255,
      "grad_norm": 0.023589907214045525,
      "learning_rate": 7.346402283310801e-06,
      "loss": 0.0011,
      "step": 34600
    },
    {
      "epoch": 3.9094186570527265,
      "grad_norm": 0.024126427248120308,
      "learning_rate": 7.271293375394321e-06,
      "loss": 0.0012,
      "step": 34700
    },
    {
      "epoch": 3.920684993240198,
      "grad_norm": 0.05598466470837593,
      "learning_rate": 7.196184467477843e-06,
      "loss": 0.0012,
      "step": 34800
    },
    {
      "epoch": 3.9319513294276702,
      "grad_norm": 0.0459243580698967,
      "learning_rate": 7.121075559561364e-06,
      "loss": 0.0013,
      "step": 34900
    },
    {
      "epoch": 3.943217665615142,
      "grad_norm": 0.009329085238277912,
      "learning_rate": 7.045966651644885e-06,
      "loss": 0.002,
      "step": 35000
    },
    {
      "epoch": 3.954484001802614,
      "grad_norm": 0.019516170024871826,
      "learning_rate": 6.970857743728406e-06,
      "loss": 0.0017,
      "step": 35100
    },
    {
      "epoch": 3.9657503379900856,
      "grad_norm": 0.010564402677118778,
      "learning_rate": 6.895748835811928e-06,
      "loss": 0.0012,
      "step": 35200
    },
    {
      "epoch": 3.977016674177557,
      "grad_norm": 0.0048065707087516785,
      "learning_rate": 6.8206399278954486e-06,
      "loss": 0.0013,
      "step": 35300
    },
    {
      "epoch": 3.9882830103650293,
      "grad_norm": 0.10143474489450455,
      "learning_rate": 6.745531019978969e-06,
      "loss": 0.0015,
      "step": 35400
    },
    {
      "epoch": 3.9995493465525014,
      "grad_norm": 0.011785211972892284,
      "learning_rate": 6.670422112062491e-06,
      "loss": 0.0011,
      "step": 35500
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9987792618732341,
      "eval_f1": 0.9609789081074007,
      "eval_loss": 0.0068821837194263935,
      "eval_precision": 0.9516177804656789,
      "eval_recall": 0.9705260375363468,
      "eval_runtime": 159.8473,
      "eval_samples_per_second": 92.419,
      "eval_steps_per_second": 2.89,
      "step": 35504
    },
    {
      "epoch": 4.010815682739973,
      "grad_norm": 0.026470286771655083,
      "learning_rate": 6.595313204146012e-06,
      "loss": 0.0008,
      "step": 35600
    },
    {
      "epoch": 4.022082018927445,
      "grad_norm": 0.3508017361164093,
      "learning_rate": 6.520204296229533e-06,
      "loss": 0.0012,
      "step": 35700
    },
    {
      "epoch": 4.033348355114916,
      "grad_norm": 0.018292861059308052,
      "learning_rate": 6.445095388313054e-06,
      "loss": 0.001,
      "step": 35800
    },
    {
      "epoch": 4.044614691302389,
      "grad_norm": 0.04868045821785927,
      "learning_rate": 6.369986480396576e-06,
      "loss": 0.0012,
      "step": 35900
    },
    {
      "epoch": 4.0558810274898605,
      "grad_norm": 0.06603918969631195,
      "learning_rate": 6.294877572480096e-06,
      "loss": 0.0009,
      "step": 36000
    },
    {
      "epoch": 4.067147363677332,
      "grad_norm": 0.011671196669340134,
      "learning_rate": 6.219768664563617e-06,
      "loss": 0.001,
      "step": 36100
    },
    {
      "epoch": 4.078413699864804,
      "grad_norm": 0.008456778712570667,
      "learning_rate": 6.144659756647138e-06,
      "loss": 0.0009,
      "step": 36200
    },
    {
      "epoch": 4.089680036052275,
      "grad_norm": 0.013977011665701866,
      "learning_rate": 6.06955084873066e-06,
      "loss": 0.0013,
      "step": 36300
    },
    {
      "epoch": 4.100946372239748,
      "grad_norm": 0.03723057731986046,
      "learning_rate": 5.994441940814181e-06,
      "loss": 0.0009,
      "step": 36400
    },
    {
      "epoch": 4.1122127084272195,
      "grad_norm": 0.011986530385911465,
      "learning_rate": 5.919333032897702e-06,
      "loss": 0.0011,
      "step": 36500
    },
    {
      "epoch": 4.123479044614691,
      "grad_norm": 0.4861385226249695,
      "learning_rate": 5.844224124981222e-06,
      "loss": 0.0007,
      "step": 36600
    },
    {
      "epoch": 4.134745380802163,
      "grad_norm": 0.0010241159470751882,
      "learning_rate": 5.769115217064744e-06,
      "loss": 0.0009,
      "step": 36700
    },
    {
      "epoch": 4.146011716989635,
      "grad_norm": 0.0033741730730980635,
      "learning_rate": 5.6940063091482654e-06,
      "loss": 0.0009,
      "step": 36800
    },
    {
      "epoch": 4.157278053177107,
      "grad_norm": 0.0669623538851738,
      "learning_rate": 5.618897401231786e-06,
      "loss": 0.0007,
      "step": 36900
    },
    {
      "epoch": 4.168544389364579,
      "grad_norm": 0.026054296642541885,
      "learning_rate": 5.543788493315308e-06,
      "loss": 0.0013,
      "step": 37000
    },
    {
      "epoch": 4.17981072555205,
      "grad_norm": 0.001662532682530582,
      "learning_rate": 5.468679585398829e-06,
      "loss": 0.0011,
      "step": 37100
    },
    {
      "epoch": 4.191077061739522,
      "grad_norm": 0.015050106681883335,
      "learning_rate": 5.3935706774823494e-06,
      "loss": 0.0007,
      "step": 37200
    },
    {
      "epoch": 4.202343397926994,
      "grad_norm": 0.024561041966080666,
      "learning_rate": 5.31846176956587e-06,
      "loss": 0.0011,
      "step": 37300
    },
    {
      "epoch": 4.213609734114466,
      "grad_norm": 0.046324677765369415,
      "learning_rate": 5.243352861649392e-06,
      "loss": 0.0006,
      "step": 37400
    },
    {
      "epoch": 4.224876070301938,
      "grad_norm": 0.0003370075428392738,
      "learning_rate": 5.168243953732913e-06,
      "loss": 0.001,
      "step": 37500
    },
    {
      "epoch": 4.236142406489409,
      "grad_norm": 0.0004627181915566325,
      "learning_rate": 5.093135045816434e-06,
      "loss": 0.0009,
      "step": 37600
    },
    {
      "epoch": 4.247408742676882,
      "grad_norm": 0.0015430948697030544,
      "learning_rate": 5.018026137899955e-06,
      "loss": 0.0011,
      "step": 37700
    },
    {
      "epoch": 4.2586750788643535,
      "grad_norm": 0.021241631358861923,
      "learning_rate": 4.942917229983477e-06,
      "loss": 0.0011,
      "step": 37800
    },
    {
      "epoch": 4.269941415051825,
      "grad_norm": 0.019571758806705475,
      "learning_rate": 4.867808322066997e-06,
      "loss": 0.0007,
      "step": 37900
    },
    {
      "epoch": 4.281207751239297,
      "grad_norm": 0.01864953711628914,
      "learning_rate": 4.792699414150518e-06,
      "loss": 0.0012,
      "step": 38000
    },
    {
      "epoch": 4.292474087426768,
      "grad_norm": 0.008786965161561966,
      "learning_rate": 4.717590506234039e-06,
      "loss": 0.0007,
      "step": 38100
    },
    {
      "epoch": 4.303740423614241,
      "grad_norm": 0.0029688093345612288,
      "learning_rate": 4.642481598317561e-06,
      "loss": 0.0008,
      "step": 38200
    },
    {
      "epoch": 4.3150067598017126,
      "grad_norm": 0.02652362920343876,
      "learning_rate": 4.567372690401082e-06,
      "loss": 0.0011,
      "step": 38300
    },
    {
      "epoch": 4.326273095989184,
      "grad_norm": 0.0038171301130205393,
      "learning_rate": 4.492263782484603e-06,
      "loss": 0.0011,
      "step": 38400
    },
    {
      "epoch": 4.337539432176656,
      "grad_norm": 0.01183894369751215,
      "learning_rate": 4.417154874568124e-06,
      "loss": 0.0012,
      "step": 38500
    },
    {
      "epoch": 4.348805768364128,
      "grad_norm": 0.003765680128708482,
      "learning_rate": 4.342045966651645e-06,
      "loss": 0.0008,
      "step": 38600
    },
    {
      "epoch": 4.3600721045516,
      "grad_norm": 0.04752633348107338,
      "learning_rate": 4.266937058735166e-06,
      "loss": 0.0008,
      "step": 38700
    },
    {
      "epoch": 4.371338440739072,
      "grad_norm": 0.030062932521104813,
      "learning_rate": 4.191828150818687e-06,
      "loss": 0.0008,
      "step": 38800
    },
    {
      "epoch": 4.382604776926543,
      "grad_norm": 0.05869171395897865,
      "learning_rate": 4.116719242902209e-06,
      "loss": 0.0011,
      "step": 38900
    },
    {
      "epoch": 4.393871113114015,
      "grad_norm": 0.07225501537322998,
      "learning_rate": 4.0416103349857295e-06,
      "loss": 0.0012,
      "step": 39000
    },
    {
      "epoch": 4.405137449301487,
      "grad_norm": 0.05050065740942955,
      "learning_rate": 3.96650142706925e-06,
      "loss": 0.0009,
      "step": 39100
    },
    {
      "epoch": 4.416403785488959,
      "grad_norm": 0.05515695735812187,
      "learning_rate": 3.891392519152771e-06,
      "loss": 0.0008,
      "step": 39200
    },
    {
      "epoch": 4.427670121676431,
      "grad_norm": 0.025064434856176376,
      "learning_rate": 3.816283611236293e-06,
      "loss": 0.001,
      "step": 39300
    },
    {
      "epoch": 4.438936457863902,
      "grad_norm": 0.002563152927905321,
      "learning_rate": 3.741174703319814e-06,
      "loss": 0.0013,
      "step": 39400
    },
    {
      "epoch": 4.450202794051375,
      "grad_norm": 0.001874308567494154,
      "learning_rate": 3.666065795403335e-06,
      "loss": 0.0007,
      "step": 39500
    },
    {
      "epoch": 4.4614691302388465,
      "grad_norm": 0.01601635105907917,
      "learning_rate": 3.590956887486856e-06,
      "loss": 0.0011,
      "step": 39600
    },
    {
      "epoch": 4.472735466426318,
      "grad_norm": 0.02278866432607174,
      "learning_rate": 3.515847979570377e-06,
      "loss": 0.0008,
      "step": 39700
    },
    {
      "epoch": 4.48400180261379,
      "grad_norm": 0.09832387417554855,
      "learning_rate": 3.4407390716538983e-06,
      "loss": 0.0008,
      "step": 39800
    },
    {
      "epoch": 4.495268138801261,
      "grad_norm": 0.031919270753860474,
      "learning_rate": 3.365630163737419e-06,
      "loss": 0.0008,
      "step": 39900
    },
    {
      "epoch": 4.506534474988734,
      "grad_norm": 0.003335618181154132,
      "learning_rate": 3.2905212558209403e-06,
      "loss": 0.0011,
      "step": 40000
    },
    {
      "epoch": 4.517800811176206,
      "grad_norm": 0.013172619044780731,
      "learning_rate": 3.2154123479044615e-06,
      "loss": 0.0011,
      "step": 40100
    },
    {
      "epoch": 4.529067147363677,
      "grad_norm": 0.0346703939139843,
      "learning_rate": 3.1403034399879823e-06,
      "loss": 0.0012,
      "step": 40200
    },
    {
      "epoch": 4.540333483551149,
      "grad_norm": 0.012696263380348682,
      "learning_rate": 3.0651945320715035e-06,
      "loss": 0.0009,
      "step": 40300
    },
    {
      "epoch": 4.551599819738621,
      "grad_norm": 0.0012500332668423653,
      "learning_rate": 2.990085624155025e-06,
      "loss": 0.0008,
      "step": 40400
    },
    {
      "epoch": 4.562866155926093,
      "grad_norm": 0.030425595119595528,
      "learning_rate": 2.914976716238546e-06,
      "loss": 0.001,
      "step": 40500
    },
    {
      "epoch": 4.574132492113565,
      "grad_norm": 0.011964784935116768,
      "learning_rate": 2.839867808322067e-06,
      "loss": 0.0009,
      "step": 40600
    },
    {
      "epoch": 4.585398828301036,
      "grad_norm": 0.001512637478299439,
      "learning_rate": 2.7647589004055884e-06,
      "loss": 0.0008,
      "step": 40700
    },
    {
      "epoch": 4.596665164488508,
      "grad_norm": 0.0008080814150162041,
      "learning_rate": 2.6896499924891096e-06,
      "loss": 0.0007,
      "step": 40800
    },
    {
      "epoch": 4.6079315006759805,
      "grad_norm": 0.06855686008930206,
      "learning_rate": 2.6145410845726304e-06,
      "loss": 0.001,
      "step": 40900
    },
    {
      "epoch": 4.619197836863452,
      "grad_norm": 0.019486762583255768,
      "learning_rate": 2.5394321766561516e-06,
      "loss": 0.0007,
      "step": 41000
    },
    {
      "epoch": 4.630464173050924,
      "grad_norm": 0.03629203140735626,
      "learning_rate": 2.4643232687396728e-06,
      "loss": 0.0007,
      "step": 41100
    },
    {
      "epoch": 4.641730509238395,
      "grad_norm": 0.03078472800552845,
      "learning_rate": 2.3892143608231936e-06,
      "loss": 0.0008,
      "step": 41200
    },
    {
      "epoch": 4.652996845425868,
      "grad_norm": 0.0022108862176537514,
      "learning_rate": 2.3141054529067148e-06,
      "loss": 0.0004,
      "step": 41300
    },
    {
      "epoch": 4.6642631816133395,
      "grad_norm": 0.024030635133385658,
      "learning_rate": 2.238996544990236e-06,
      "loss": 0.0007,
      "step": 41400
    },
    {
      "epoch": 4.675529517800811,
      "grad_norm": 0.012628952041268349,
      "learning_rate": 2.1638876370737568e-06,
      "loss": 0.0007,
      "step": 41500
    },
    {
      "epoch": 4.686795853988283,
      "grad_norm": 0.08312994986772537,
      "learning_rate": 2.088778729157278e-06,
      "loss": 0.0008,
      "step": 41600
    },
    {
      "epoch": 4.698062190175754,
      "grad_norm": 0.020220652222633362,
      "learning_rate": 2.013669821240799e-06,
      "loss": 0.0012,
      "step": 41700
    },
    {
      "epoch": 4.709328526363227,
      "grad_norm": 0.07838046550750732,
      "learning_rate": 1.93856091332432e-06,
      "loss": 0.0008,
      "step": 41800
    },
    {
      "epoch": 4.720594862550699,
      "grad_norm": 0.02187238074839115,
      "learning_rate": 1.8634520054078414e-06,
      "loss": 0.0006,
      "step": 41900
    },
    {
      "epoch": 4.73186119873817,
      "grad_norm": 0.0014198556309565902,
      "learning_rate": 1.7883430974913624e-06,
      "loss": 0.0008,
      "step": 42000
    },
    {
      "epoch": 4.743127534925642,
      "grad_norm": 0.05339043214917183,
      "learning_rate": 1.7132341895748836e-06,
      "loss": 0.0006,
      "step": 42100
    },
    {
      "epoch": 4.754393871113114,
      "grad_norm": 0.034834153950214386,
      "learning_rate": 1.6381252816584046e-06,
      "loss": 0.0007,
      "step": 42200
    },
    {
      "epoch": 4.765660207300586,
      "grad_norm": 0.0076164924539625645,
      "learning_rate": 1.563016373741926e-06,
      "loss": 0.0006,
      "step": 42300
    },
    {
      "epoch": 4.776926543488058,
      "grad_norm": 0.00017920728714670986,
      "learning_rate": 1.487907465825447e-06,
      "loss": 0.0006,
      "step": 42400
    },
    {
      "epoch": 4.788192879675529,
      "grad_norm": 0.0002850430610124022,
      "learning_rate": 1.412798557908968e-06,
      "loss": 0.0012,
      "step": 42500
    },
    {
      "epoch": 4.799459215863001,
      "grad_norm": 0.0013804947957396507,
      "learning_rate": 1.3376896499924892e-06,
      "loss": 0.0008,
      "step": 42600
    },
    {
      "epoch": 4.8107255520504735,
      "grad_norm": 0.006686200853437185,
      "learning_rate": 1.2625807420760102e-06,
      "loss": 0.0007,
      "step": 42700
    },
    {
      "epoch": 4.821991888237945,
      "grad_norm": 0.06968794763088226,
      "learning_rate": 1.1874718341595312e-06,
      "loss": 0.0005,
      "step": 42800
    },
    {
      "epoch": 4.833258224425417,
      "grad_norm": 0.0376853384077549,
      "learning_rate": 1.1123629262430524e-06,
      "loss": 0.0009,
      "step": 42900
    },
    {
      "epoch": 4.844524560612888,
      "grad_norm": 0.0009682429954409599,
      "learning_rate": 1.0372540183265736e-06,
      "loss": 0.0008,
      "step": 43000
    },
    {
      "epoch": 4.855790896800361,
      "grad_norm": 0.013899792917072773,
      "learning_rate": 9.621451104100946e-07,
      "loss": 0.0008,
      "step": 43100
    },
    {
      "epoch": 4.8670572329878325,
      "grad_norm": 0.020715776830911636,
      "learning_rate": 8.870362024936158e-07,
      "loss": 0.0012,
      "step": 43200
    },
    {
      "epoch": 4.878323569175304,
      "grad_norm": 0.01167201902717352,
      "learning_rate": 8.119272945771368e-07,
      "loss": 0.0012,
      "step": 43300
    },
    {
      "epoch": 4.889589905362776,
      "grad_norm": 0.0035359093453735113,
      "learning_rate": 7.368183866606579e-07,
      "loss": 0.0021,
      "step": 43400
    },
    {
      "epoch": 4.9008562415502475,
      "grad_norm": 0.03798142075538635,
      "learning_rate": 6.617094787441791e-07,
      "loss": 0.0008,
      "step": 43500
    },
    {
      "epoch": 4.91212257773772,
      "grad_norm": 0.006595660466700792,
      "learning_rate": 5.866005708277002e-07,
      "loss": 0.0008,
      "step": 43600
    },
    {
      "epoch": 4.923388913925192,
      "grad_norm": 0.0751868188381195,
      "learning_rate": 5.114916629112212e-07,
      "loss": 0.0009,
      "step": 43700
    },
    {
      "epoch": 4.934655250112663,
      "grad_norm": 0.04182949662208557,
      "learning_rate": 4.363827549947424e-07,
      "loss": 0.0008,
      "step": 43800
    },
    {
      "epoch": 4.945921586300135,
      "grad_norm": 0.0171279888600111,
      "learning_rate": 3.612738470782635e-07,
      "loss": 0.0007,
      "step": 43900
    },
    {
      "epoch": 4.957187922487607,
      "grad_norm": 0.0023611390497535467,
      "learning_rate": 2.861649391617846e-07,
      "loss": 0.0008,
      "step": 44000
    },
    {
      "epoch": 4.968454258675079,
      "grad_norm": 0.00435097049921751,
      "learning_rate": 2.110560312453057e-07,
      "loss": 0.001,
      "step": 44100
    },
    {
      "epoch": 4.979720594862551,
      "grad_norm": 0.002150747226551175,
      "learning_rate": 1.359471233288268e-07,
      "loss": 0.0009,
      "step": 44200
    },
    {
      "epoch": 4.990986931050022,
      "grad_norm": 0.0014562268042936921,
      "learning_rate": 6.08382154123479e-08,
      "loss": 0.0006,
      "step": 44300
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9988855173130046,
      "eval_f1": 0.9641027886004465,
      "eval_loss": 0.006676720455288887,
      "eval_precision": 0.9580215764746824,
      "eval_recall": 0.9702616970658208,
      "eval_runtime": 158.8504,
      "eval_samples_per_second": 92.999,
      "eval_steps_per_second": 2.908,
      "step": 44380
    },
    {
      "epoch": 5.0,
      "step": 44380,
      "total_flos": 1.8552525389841302e+17,
      "train_loss": 0.0040373358081433625,
      "train_runtime": 14136.0184,
      "train_samples_per_second": 50.227,
      "train_steps_per_second": 3.139
    }
  ],
  "logging_steps": 100,
  "max_steps": 44380,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.8552525389841302e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
