{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86a72d6-3a57-4ee9-85c2-8b453664c6c7",
   "metadata": {},
   "source": [
    "# Inference for Citation Extraction\n",
    "\n",
    "This notebook is for sanity-checking and testing inference for the citation and extraction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c498261-2e42-4397-b7a2-9d3691544fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f5705-9b23-421d-bae6-04d07e807432",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import whatever we need for running inference. For now, this is just the function\n",
    "to output raw labels from a string input. It's also worth checking what the default\n",
    "loading location is for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075728a6-28d4-4536-b3ab-1e853b4ca96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/archytas/Projects/perseus-citation-model/outputs/models/extraction\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "from perscit_model.extraction.inference import MODEL_SAVE_DIR, InferenceModel\n",
    "\n",
    "print(MODEL_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986b3128-0a47-4072-bc7c-3d2cde4298c5",
   "metadata": {},
   "source": [
    "## Expected input text without `<bibl>`, `<cit>`, and `<quote>` tags\n",
    "\n",
    "The cell below tests inference on text input in the expected format, with all XML tags that explicitly give\n",
    "the desired labels removed. We can see that it works quite well. This text is from the training data itself,\n",
    "so we should also look at text from the test data.\n",
    "\n",
    "TODO: reconstruct XML tags based on labels and reconstruct string. Give metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15831eb0-6459-4eff-8b34-b0d42ad54ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/archytas/Projects/perseus-citation-model/.venv/lib/python3.13/site-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-BIBL', 'I-BIBL', 'I-BIBL', 'I-BIBL', 'I-BIBL', 'I-BIBL', 'I-BIBL', 'I-BIBL', 'I-BIBL', 'I-BIBL', 'I-BIBL', 'I-BIBL', 'B-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'I-QUOTE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "text = \"direct or reported, is a regular Greek idiom. Cf. Plato, Rep. 332 D<foreign lang=\\\"greek\\\">h( ti/si ti/ a)podidou=sa te/xnh</foreign>; Soph. <title>El.</title> 751 oi(=' e)/rga dra/sas oi(=a lagxa/nei kaka/. In instances like the present\"\n",
    "model = InferenceModel()\n",
    "tokens, labels = model.process_text(text)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af50605-83e4-4d8d-b93f-4ae5dbcc8bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct or reported, is a regular Greek idiom. Cf. Plato, Rep. 332 D<foreign lang=\"greek\">h( ti/si ti/ a)podidou=sa te/xnh</foreign>;<bibl> Soph. <title>El.</title> 751</bibl><quote> oi(=\\' e)/rga dra/sas oi(=a lagxa/nei kaka/.</quote> In instances like the present'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.insert_tags_into_xml(text, tokens, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa626f-ae00-4fae-b9a3-4a2d4f36dd5b",
   "metadata": {},
   "source": [
    "## Text with `<bibl>`, `<cit>`, and `<quote>` tags\n",
    "\n",
    "This tests the behaviour of model inference where the labels are present in the data\n",
    "as XML tags. This is mostly just to diagnose data leakage issues: it's not in itself very important\n",
    "whether the model identifies these tokens correctly or not.\n",
    "\n",
    "What we see here is that the model overlooks anything between`<bib>`, `<cit>`, and `<quote>` tags.\n",
    "This does suggest that the model is looking for a pretty precise format for identifying these elements:\n",
    "including explicit labels as XML tags is enough to throw off inference. Because the model ignores\n",
    "citations where they are already labelled as such in the XML, it might be possible to process\n",
    "XML documents simply by passing them through the model and inserting tags accordingly. This will work\n",
    "as long as the model consistently ignores already-tagged citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c77f9b5-fdfd-4956-a3ff-22b0f28ab3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "text = \"direct or reported, is a regular Greek idiom. Cf. <bibl n=\\\"Plat. Rep. 332D\\\">Plato, Rep. 332 D</bibl> <foreign lang=\\\"greek\\\">h( ti/si ti/ a)podidou=sa te/xnh</foreign>;  <cit><bibl n=\\\"Soph. El. 751\\\">Soph. <title>El.</title> 751</bibl> <quote lang=\\\"greek\\\">oi(=' e)/rga dra/sas oi(=a lagxa/nei kaka/</quote></cit>. In instances like the present\"\n",
    "tokens, labels = model.process_text(text)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8dc429c-f2a3-4548-884b-3cd6fc8e2321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct or reported, is a regular Greek idiom. Cf. <bibl n=\"Plat. Rep. 332D\">Plato, Rep. 332 D</bibl> <foreign lang=\"greek\">h( ti/si ti/ a)podidou=sa te/xnh</foreign>;  <cit><bibl n=\"Soph. El. 751\">Soph. <title>El.</title> 751</bibl> <quote lang=\"greek\">oi(=\\' e)/rga dra/sas oi(=a lagxa/nei kaka/</quote></cit>. In instances like the present'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.insert_tags_into_xml(text, tokens, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5621f4-16eb-4736-978f-fbc843bbd2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[\"input_ids\"].dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b57346-7da8-47b9-90af-e68240f65543",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = [ids[mask] for ids, mask in zip(tokens[\"input_ids\"], tokens[\"attention_mask\"].bool())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d4315-6fbb-4fbc-8946-5b55d25ad90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfcf70d-76a5-4ab4-9823-7f35b3bf65e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"microsoft/deberta-v3-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8c908-db6f-4dc2-97a4-69c6a34d6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc592d-ee9c-4d44-bd43-d2f9e2d0c56b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
