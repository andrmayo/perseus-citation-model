# Model
model_name: microsoft/deberta-v3-base
max_length: 512

# Optimization
learning_rate: 0.00003
weight_decay: 0.01
warmup_ratio: 0.1
gradient_accumulation_steps: 1

# Training
num_train_epochs: 5
per_device_train_batch_size: 16
per_device_eval_batch_size: 32
fp16: true
dataloader_num_workers: 4

# Evaluation
eval_strategy: epoch
metric_for_best_model: eval_f1
greater_is_better: true
load_best_model_at_end: true

# Early stopping
early_stopping_patience: 3
early_stopping_threshold: 0.0001

# Checkpointing
save_strategy: epoch
save_total_limit: 3
output_dir: outputs/extraction

# Logging
logging_strategy: steps
logging_steps: 100
report_to: none

# Reproducibility
seed: 1234

# Data splitting ratios (only used when splitting raw data)
train_ratio: 0.8
val_ratio: 0.1
test_ratio: 0.1
